Circuits.csv
  from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType
  circuits_schema = StructType(fields=[
                                    StructField("circuitId", IntegerType(), False),
                                     StructField("circuitRef", StringType(), True),
                                     StructField("name", StringType(), True),
                                     StructField("location", StringType(), True),
                                     StructField("country", StringType(), True),
                                     StructField("lat", DoubleType(), True),
                                     StructField("lng", DoubleType(), True),
                                     StructField("alt", IntegerType(), True),
                                     StructField("url", StringType(), True)
                                     ])
  circuits_df = spark.read.option("header", True).schema(circuits_schema).csv("dbfs:/mnt/files/raw/circuits.csv")
  circuits_selected_df = circuits_df.select("circuitId", "circuitRef", "name", "location", "country", "lat", "lng", "alt")
  circuits_renamed_df = circuits_selected_df.withColumnRenamed("circuitId", "circuit_id") \
                                          .withColumnRenamed("circuitRef", "circuit_ref") \
                                          .withColumnRenamed("lat", "latitude") \
                                          .withColumnRenamed("lng", "longitude") \
                                          .withColumnRenamed("alt", "altitude")
  from pyspark.sql.functions import current_timestamp
  circuits_final_df = circuits_renamed_df.withColumn("ingestion_date", current_timestamp( ))
  circuits_final_df.write.mode("overwrite").parquet("dbfs:/mnt/files/clean/circuits")

Races.csv
  from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType
  from pyspark.sql.functions import current_timestamp, to_timestamp,concat, col, lit
  races_schema = StructType(fields=[
                                    StructField("raceId", IntegerType(), False),
                                    StructField("year", IntegerType(), True),
                                    StructField("round", IntegerType(), True),
                                    StructField("circuitId", IntegerType(), True),
                                    StructField("name", StringType(), True),
                                    StructField("date", DateType(), True),
                                    StructField("time", StringType(), True),
                                    StructField("url", StringType(), True)
                                    ])
  races_df = spark.read.option("header", True).schema(races_schema).csv('/mnt/files/raw/races.csv')
  races_with_timestamp_df = races_df.withColumn("ingestion_date", current_timestamp())\
    .withColumn("race_timestamp", to_timestamp(concat(col('date'), lit(' '), col('time')), 'yyyy-MM-dd HH:mm:ss'))
  races_selected_df = races_with_timestamp_df.select(col('raceId').alias('race_id'), col('year').alias('race_year'), col('round'), col('circuitId').alias('circuit_id'), col('name'), col('ingestion_date'), col('race_timestamp'))
  races_selected_df.write.mode("overwrite").partitionBy('race_year').parquet("dbfs:/mnt/files/clean/races")

Constructors.json
  constructors_schema = StructType(fields=[
                                    StructField("constructorId", IntegerType(), False),
                                    StructField("constructorRef", StringType(), True),
                                    StructField("name", StringType(), True),
                                    StructField("nationality", StringType(), True),
                                    StructField("url", StringType(), True)
                                    ])
  constructors_df = spark.read.schema(constructors_schema).json('/mnt/files/raw/constructors.json')
  constructor_dropped_df = constructors_df.drop(col('url'))
  constructor_final_df = constructor_dropped_df.withColumnRenamed('constructorId', 'constructor_id')\
    .withColumnRenamed('constructorRef', 'constructor_ref')\
        .withColumn('ingestion_date', current_timestamp())
  constructor_final_df.write.mode("overwrite").parquet('/mnt/files/clean/constructors')

Drivers.json
  name_schema = StructType(fields=[ StructField("forename", StringType(), True),
                                  StructField("surname", StringType(), True)])
  drivers_schema = StructType(fields=[
                                    StructField("driverId", IntegerType(), False),
                                    StructField("driverRef", StringType(), True),
                                    StructField("number", IntegerType(), True),
                                    StructField("code", StringType(), True),
                                    StructField("name", name_schema, True),
                                    StructField("dob", DateType(), True),
                                    StructField("nationality", StringType(), True),
                                    StructField("url", StringType(), True) ])
  drivers_df = spark.read.schema(drivers_schema).json('/mnt/files/raw/drivers.json')
  drivers_with_columns_df = drivers_df.withColumnRenamed('driverId', 'driver_id')\
    .withColumnRenamed('driverRef', 'driver_ref')\
        .withColumn('ingestion_date', current_timestamp())\
            .withColumn('name', concat(col('name.forename'), lit(' '), col('name.surname')))

  drivers_final_df = drivers_with_columns_df.drop(col('url'))
  drivers_final_df.write.mode("overwrite").parquet('/mnt/files/clean/drivers')

Results.json
  from pyspark.sql.types import FloatType
  results_schema = StructType(fields=[
        StructField("resultId", IntegerType(), False),
        StructField("raceId", IntegerType(), True),
        StructField("driverId", IntegerType(), True),
        StructField("constructorId", IntegerType(), True),
        StructField("number", IntegerType(), True),
        StructField("grid", IntegerType(), True),
        StructField("position", IntegerType(), True),
        StructField("positionText", StringType(), True),
        StructField("positionOrder", IntegerType(), True),
        StructField("points", FloatType(), True),
        StructField("laps", IntegerType(), True),
        StructField("time", StringType(), True),
        StructField("milliseconds", IntegerType(), True),
        StructField("fastestLap", IntegerType(), True),
        StructField("rank", IntegerType(), True),
        StructField("fastestLapTime", StringType(), True),
        StructField("fastestLapSpeed", FloatType(), True),
        StructField("statusId", StringType(), True)])
    results_df = spark.read.schema(results_schema).json('/mnt/files/raw/results.json')
    results_with_columns_df = results_df.withColumnRenamed('resultId', 'result_id')\
    .withColumnRenamed('raceId', 'race_id')\
        .withColumnRenamed('driverId', 'driver_id')\
            .withColumnRenamed('constructorId', 'constructor_id')\
                .withColumnRenamed('positionText', 'position_text')\
                    .withColumnRenamed('positionOrder', 'position_order')\
                        .withColumnRenamed('fastestLap', 'fastest_lap')\
                            .withColumnRenamed('fastestLapTime', 'fastest_lap_time')\
                                .withColumnRenamed('fastestLapSpeed', 'fastest_lap_speed')\
                                    .withColumn('ingestion_date', current_timestamp())

    results_final_df = results_with_columns_df.drop(col('statusId'))
    results_final_df.write.mode("overwrite").parquet('/mnt/files/clean/results')

Pitstops.json Multi-line
  pitstops_schema = StructType(fields=[
        StructField("raceId", IntegerType(), False),
        StructField("driverId", IntegerType(), True),
        StructField("stop", StringType(), True),
        StructField("lap", IntegerType(), True),
        StructField("time", StringType(), True),
        StructField("duration", StringType(), True),
        StructField("milliseconds", IntegerType(), True) ])
  pitstops_df = spark.read.schema(pitstops_schema).option("multiline", True).json('/mnt/files/raw/pit_stops.json')
  final_df = pitstops_df.withColumnRenamed('raceId', 'race_id')\
    .withColumnRenamed('driverId', 'driver_id')\
        .withColumn('ingestion_date', current_timestamp())
  final_df.write.mode("overwrite").parquet('/mnt/files/clean/pitstops')

Laptimes.csv In Folder
  laptimes_schema = StructType(fields=[
        StructField("raceId", IntegerType(), False),
        StructField("driverId", IntegerType(), True),
        StructField("lap", IntegerType(), True),
        StructField("position", IntegerType(), True),
        StructField("time", StringType(), True),
        StructField("milliseconds", IntegerType(), True) ])
  laptimes_df = spark.read.schema(laptimes_schema).csv('/mnt/files/raw/laptimes')
  final_df = laptimes_df.withColumnRenamed('raceId', 'race_id')\
    .withColumnRenamed('driverId', 'driver_id')\
        .withColumn('ingestion_date', current_timestamp())
  final_df.write.mode("overwrite").parquet('/mnt/files/clean/laptimes')

Qualifying.json
  qualifying_schema = StructType(fields=[
        StructField("qualifyId", IntegerType(), False),
        StructField("raceId", IntegerType(), True),
        StructField("driverId", IntegerType(), True),
        StructField("constructorId", IntegerType(), True),
        StructField("number", IntegerType(), True),
        StructField("position", IntegerType(), True),
        StructField("q1", StringType(), True),
        StructField("q2", StringType(), True),
        StructField("q3", StringType(), True) ])
    qualifying_df = spark.read.schema(qualifying_schema).option("multiline", True).json('/mnt/files/raw/qualifying')
    final_df = qualifying_df.withColumnRenamed('raceId', 'race_id')\
      .withColumnRenamed('driverId', 'driver_id')\
        .withColumnRenamed('constructorId', 'constructor_id')\
            .withColumn('ingestion_date', current_timestamp())\
                .withColumnRenamed('qualifyId', 'qualify_id')
    final_df.write.mode("overwrite").parquet('/mnt/files/clean/qualifying')
